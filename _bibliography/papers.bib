---
---

@ARTICLE{10538419,
  author={Knopke, Maceon and Zhu, Liguo and Corke, Peter and Zhang, Fangyi},
  journal={IEEE Robotics and Automation Letters (RA-L)}, 
  title={Towards Assessing Compliant Robotic Grasping From First-Object Perspective via Instrumented Objects}, 
  year={2024},
  volume={9},
  number={7},
  pages={6320--6327},
  keywords={Sensors;Faces;Magnetic sensors;Force;Magnets;Grasping;Three-dimensional displays;Grasping;methods and tools for robot system design;soft sensors and actuators},
  doi={10.1109/LRA.2024.3405371},
  selected={true},
  abstract={Grasping compliant objects is difficult for robots - applying too little force may cause the grasp to fail, while too much force may lead to object damage. A robot needs to apply the right amount of force to quickly and confidently grasp the objects so that it can perform the required task. Although some methods have been proposed to tackle this issue, performance assessment is still a problem for directly measuring object property changes and possible damage. To fill the gap, a new concept is introduced in this paper to assess compliant robotic grasping using instrumented objects. A proof-of-concept design is proposed to measure the force applied on a cuboid object from a first-object perspective. The design can detect multiple contact locations and applied forces on its surface by using multiple embedded 3D Hall sensors to detect deformation relative to embedded magnets. The contact estimation is achieved by interpreting the Hall-effect signals using neural networks. In comprehensive experiments, the design achieved good performance in estimating contacts from each single face of the cuboid and decent performance in detecting contacts from multiple faces when being used to evaluate grasping from a parallel jaw gripper, demonstrating the effectiveness of the design and the feasibility of the concept.}
  }

  @INPROCEEDINGS{10342262,
  author={Zhang, Fangyi and Corke, Peter},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Re-Evaluating Parallel Finger-Tip Tactile Sensing for Inferring Object Adjectives: An Empirical Study}, 
  year={2023},
  pages={8951-8957},
  keywords={Tactile sensors;Sensors;Biosensors;Intelligent robots},
  doi={10.1109/IROS55552.2023.10342262},
  selected={true},
  abstract={Finger-tip tactile sensors are increasingly used for robotic sensing to establish stable grasps and to infer object properties. Promising performance has been shown in a number of works for inferring adjectives that describe the object, but there remains a question about how each taxel contributes to the performance. This paper explores this question with empirical experiments, leading insights for future finger-tip tactile sensor usage and design.}
  }

@inproceedings{wang2022robust,
  author={Yaohua Wang and Fangyi Zhang and Ming Lin and Senzhang Wang and Xiuyu Sun and Rong Jin},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages = {32083--32096},
  publisher = {Curran Associates, Inc.},
  title = {Robust Graph Structure Learning via Multiple Statistical Tests},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/cf7700139af1fa346d2f57f1f5c26c18-Paper-Conference.pdf},
  volume = {35},
  year = {2022},
  selected={true},
  abstract={Graph structure learning aims to learn connectivity in a graph from data. It is particularly important for many computer vision related tasks since no explicit graph structure is available for images for most cases. A natural way to construct a graph among images is to treat each image as a node and assign pairwise image similarities as weights to corresponding edges. It is well known that pairwise similarities between images are sensitive to the noise in feature representations, leading to unreliable graph structures. We address this problem from the viewpoint of statistical tests. By viewing the feature vector of each node as an independent sample, the decision of whether creating an edge between two nodes based on their similarity in feature representation can be thought as a single statistical test. To improve the robustness in the decision of creating an edge, multiple samples are drawn and integrated by multiple statistical tests to generate a more reliable similarity measure, consequentially more reliable graph structure. The corresponding elegant matrix form named îˆ®-Attention is designed for efficiency. The effectiveness of multiple tests for graph structure learning is verified both theoretically and empirically on multiple clustering and ReID benchmark datasets.}
}

@inproceedings{wang2022adanets,
  title={Ada-{NETS}: Face Clustering via Adaptive Neighbour Discovery in the Structure Space},
  author={Yaohua Wang and Yaobin Zhang and Fangyi Zhang and Senzhang Wang and Ming Lin and Yuqi Zhang and Xiuyu Sun},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022},
  url={https://openreview.net/forum?id=QJWVP4CTmW4},
  selected={true},
  abstract={Face clustering has attracted rising research interest recently to take advantage of massive amounts of face images on the web. State-of-the-art performance has been achieved by Graph Convolutional Networks (GCN) due to their powerful representation capacity. However, existing GCN-based methods build face graphs mainly according to kNN relations in the feature space, which may lead to a lot of noise edges connecting two faces of different classes. The face features will be polluted when messages pass along these noise edges, thus degrading the performance of GCNs. In this paper, a novel algorithm named Ada-NETS is proposed to cluster faces by constructing clean graphs for GCNs. In Ada-NETS, each face is transformed to a new structure space, obtaining robust features by considering face features of the neighbour images. Then, an adaptive neighbour discovery strategy is proposed to determine a proper number of edges connecting to each face image. It significantly reduces the noise edges while maintaining the good ones to build a graph with clean yet rich edges for GCNs to cluster faces. Experiments on multiple public clustering datasets show that Ada-NETS significantly outperforms current state-of-the-art methods, proving its superiority and generalization.}
}

@inproceedings{yang2021gcn,
  title={GCN-Based Linkage Prediction for Face Clusteringon Imbalanced Datasets: An Empirical Study},
  author={Huafeng Yang and Xingjian Chen and Fangyi Zhang and Guangyue Hei and Yunjie Wang and Rong Du},
  booktitle={Workshops of the International Joint Conference on Artificial Intelligence},
  year={2021},
  url={https://arxiv.org/abs/2107.02477v2},
  abstract={In recent years, benefiting from the expressivepower of Graph Convolutional Networks (GCNs),significant breakthroughs have been made in faceclustering. However, rare attention has been paidto GCN-based clustering on imbalanced data. Al-though imbalance problem has been extensivelystudied, the impact of imbalanced data on GCN-based linkage prediction task is quite different,which would cause problems in two aspects: im-balanced linkage labels and biased graph represen-tations. The problem of imbalanced linkage labelsis similar to that in image classification task, but thelatter is a particular problem in GCN-based clus-tering via linkage prediction. Significantly biasedgraph representations in training can cause catas-trophic overfitting of a GCN model. To tacklethese problems, we evaluate the feasibility of thoseexisting methods for imbalanced image classifica-tion problem on graphs with extensive experiments,and present a new method to alleviate the imbal-anced labels and also augment graph representa-tions using a Reverse-Imbalance Weighted Sam-pling (RIWS) strategy, followed with insightfulanalyses and discussions. A series of imbalancedbenchmark datasets synthesized from MS-Celeb-1M and DeepFashion will be openly available.}
}

@inproceedings{doi:10.1137/1.9781611977653.ch74,
  author = {Huafeng Yang and Qijie Shen and Xingjian Chen and Fangyi Zhang and Rong Du},
  title = {A Linkage-based Doubly Imbalanced Graph Learning Framework for Face Clustering},
  booktitle = {SIAM International Conference on Data Mining},
  pages = {658--666},
  year = {2023},
  doi = {10.1137/1.9781611977653.ch74},
  URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977653.ch74},
  eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977653.ch74}
}

@article{zhang2019adversarial,
  author = {Fangyi Zhang and J{\"u}rgen Leitner and Zongyuan Ge and Michael Milford and Peter Corke},
  title = {Adversarial discriminative sim-to-real transfer of visuo-motor policies},
  journal = {The International Journal of Robotics Research (IJRR)},
  volume = {38},
  number = {10--11},
  pages = {1229--1245},
  year = {2019},
  doi = {10.1177/0278364919870227},
  URL = {https://doi.org/10.1177/0278364919870227},
  selected={true},
  abstract={Various approaches have been proposed to learn visuo-motor policies for real-world robotic applications. One solution is first learning in simulation then transferring to the real world. In the transfer, most existing approaches need real-world images with labels. However, the labelling process is often expensive or even impractical in many robotic applications. In this paper, we propose an adversarial discriminative sim-to-real transfer approach to reduce the cost of labelling real data. The effectiveness of the approach is demonstrated with modular networks in a table-top object reaching task where a 7 DoF arm is controlled in velocity mode to reach a blue cuboid in clutter through visual observations. The adversarial transfer approach reduced the labelled real data requirement by 50%. Policies can be transferred to real environments with only 93 labelled and 186 unlabelled real images. The transferred visuo-motor policies are robust to novel (not seen in training) objects in clutter and even a moving target, achieving a 97.8% success rate and 1.8 cm control accuracy.}
}

@INPROCEEDINGS{leitner2017acrv,  
  author={J{\"u}rgen Leitner and Adam W. Tow and Niko S{\"u}nderhauf and Jake E. Dean and Joseph W. Durham and Matthew Cooper and Markus Eich and Christopher Lehnert and Ruben Mangels and Christopher McCool and Peter T. Kujala and Lachlan Nicholson and Trung Pham and James Sergeant and Liao Wu and Fangyi Zhang and Ben Upcroft and Peter Corke},  
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},   
  title={The ACRV picking benchmark: A robotic shelf picking benchmark to foster reproducible research},   
  year={2017}, 
  pages={4705--4712},  
  doi={10.1109/ICRA.2017.7989545},
  selected={true},
  abstract={Robotic challenges like the Amazon Picking Challenge (APC) or the DARPA Challenges are an established and important way to drive scientific progress. They make research comparable on a well-defined benchmark with equal test conditions for all participants. However, such challenge events occur only occasionally, are limited to a small number of contestants, and the test conditions are very difficult to replicate after the main event. We present a new physical benchmark challenge for robotic picking: the ACRV Picking Benchmark (APB). Designed to be reproducible, it consists of a set of 42 common objects, a widely available shelf, and exact guidelines for object arrangement using stencils. A well-defined evaluation protocol enables the comparison of \emph{complete} robotic systems -- including perception and manipulation -- instead of sub-systems only. Our paper also describes and reports results achieved by an open baseline system based on a Baxter robot.}
}

@inproceedings{zhang2017acra,
  title={Modular Deep Q Networks for Sim-to-real Transfer of Visuo-motor Policies},
  author={Fangyi Zhang and J{\"u}rgen Leitner and Michael Milford and Peter Corke},
  booktitle={Australasian Conference on Robotics and Automation (ACRA)},
  month={December},
  year={2017},
  institution={Sydney, Australia},
  URL={http://www.araa.asn.au/acra/acra2017/papers/pap146s1-file1.pdf}
}

@inproceedings{zhang2017cvpr,
  author={Fangyi Zhang and J{\"u}rgen Leitner and Michael Milford and Peter Corke},
  title = {Tuning Modular Networks With Weighted Losses for Hand-Eye Coordination},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={496--497},
  month = {July},
  institution={Honolulu, Hawaii, USA},
  url={http://openaccess.thecvf.com/content_cvpr_2017_workshops/w5/papers/Zhang_Tuning_Modular_Networks_CVPR_2017_paper.pdf},
  year={2017},
  doi={10.1109/CVPRW.2017.74}
}

@inproceedings{zhang2015towards,
  title={Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control},
  author={Fangyi Zhang and J{\"u}rgen Leitner and Michael Milford and Ben Upcroft and Peter Corke},
  booktitle={Australasian Conference on Robotics and Automation (ACRA)},
  month={December},
  year={2015},
  institution={Canberra, Australia},
  url={https://www.araa.asn.au/acra/acra2015/papers/pap168.pdf}
}

@inproceedings{zhang2015asynchronous,
  title={Asynchronous blind signal decomposition using tiny-length code for visible light communication-based indoor localization},
  author={Fangyi Zhang and Kejie Qiu and Ming Liu},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  pages={28002805},
  year={2015},
  organization={IEEE},
  doi={10.1109/ICRA.2015.7139580}
}

@inproceedings{qiu2015visible,
  title={Visible light communication-based indoor localization using Gaussian process},
  author={Kejie Qiu and Fangyi Zhang and Ming Liu},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={3125--3130},
  organization={IEEE},
  year={2015},
  doi={10.1109/IROS.2015.7353809}
}

@article{qiu2016let,
  title={Let the light guide us: VLC-based localization},
  author={Kejie Qiu and Fangyi Zhang and Ming Liu},
  journal={IEEE Robotics \& Automation Magazine},
  volume={23},
  number={4},
  pages={174--183},
  year={2016},
  publisher={IEEE},
  doi={10.1109/MRA.2016.2591833}
}

@INPROCEEDINGS{7294062,
  author={Kejie Qiu and Fangyi Zhang and Ming Liu},
  booktitle={IEEE International Conference on Automation Science and Engineering}, 
  title={Visible light communication-based indoor environment modeling and metric-free path planning}, 
  year={2015},
  pages={200--205},
  doi={10.1109/CoASE.2015.7294062}
}

@inproceedings{10.1145/3474085.3475698,
  author = {Zhenhong Sun and Zhiyu Tan and Xiuyu Sun and Fangyi Zhang and Yichen Qian and Dongyang Li and Hao Li},
  title = {Interpolation Variable Rate Image Compression},
  year = {2021},
  isbn = {9781450386517},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3474085.3475698},
  doi = {10.1145/3474085.3475698},
  booktitle = {ACM International Conference on Multimedia},
  pages = {5574--5582},
  numpages = {9},
  keywords = {learned image compression, interpolation variable rate control, convolutional neural network (cnn)},
  location = {Virtual Event, China}
}

@INPROCEEDINGS{9746149,
  author={Dongyang Li and Zhenhong Sun and Zhiyu Tan and Xiuyu Sun and Fangyi Zhang and Yichen Qian and Hao Li},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  title={Jmpnet: Joint Motion Prediction for Learning-Based Video Compression},
  year={2022},
  pages={1855--1859},
  doi={10.1109/ICASSP43922.2022.9746149}
}