---
---
@ARTICLE{10538419,
  title={Towards Assessing Compliant Robotic Grasping From First-Object Perspective via Instrumented Objects}, 
  author={Knopke, Maceon and Zhu, Liguo and Corke, Peter and Zhang, Fangyi},
  journal={IEEE Robotics and Automation Letters (RA-L)}, 
  year={2024},
  volume={9},
  number={7},
  pages={6320--6327},
  keywords={Sensors;Faces;Magnetic sensors;Force;Magnets;Grasping;Three-dimensional displays;Grasping;methods and tools for robot system design;soft sensors and actuators},
  doi={10.1109/LRA.2024.3405371},
  selected={true},
  pdf={https://ieeexplore.ieee.org/abstract/document/10538419},
  preview={Towards_Assessing.png},
  abstract={Grasping compliant objects is difficult for robots - applying too little force may cause the grasp to fail, while too much force may lead to object damage. A robot needs to apply the right amount of force to quickly and confidently grasp the objects so that it can perform the required task. Although some methods have been proposed to tackle this issue, performance assessment is still a problem for directly measuring object property changes and possible damage. To fill the gap, a new concept is introduced in this paper to assess compliant robotic grasping using instrumented objects. A proof-of-concept design is proposed to measure the force applied on a cuboid object from a first-object perspective. The design can detect multiple contact locations and applied forces on its surface by using multiple embedded 3D Hall sensors to detect deformation relative to embedded magnets. The contact estimation is achieved by interpreting the Hall-effect signals using neural networks. In comprehensive experiments, the design achieved good performance in estimating contacts from each single face of the cuboid and decent performance in detecting contacts from multiple faces when being used to evaluate grasping from a parallel jaw gripper, demonstrating the effectiveness of the design and the feasibility of the concept.}
  }

  @INPROCEEDINGS{10342262,
  title={Re-Evaluating Parallel Finger-Tip Tactile Sensing for Inferring Object Adjectives: An Empirical Study}, 
  author={Zhang, Fangyi and Corke, Peter},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  year={2023},
  pages={8951-8957},
  keywords={Tactile sensors;Sensors;Biosensors;Intelligent robots},
  doi={10.1109/IROS55552.2023.10342262},
  selected={true},
  pdf={https://ieeexplore.ieee.org/document/10342262},
  preview={re_evaluate_tactile.png},
  abstract={Finger-tip tactile sensors are increasingly used for robotic sensing to establish stable grasps and to infer object properties. Promising performance has been shown in a number of works for inferring adjectives that describe the object, but there remains a question about how each taxel contributes to the performance. This paper explores this question with empirical experiments, leading insights for future finger-tip tactile sensor usage and design.}
  }

@inproceedings{doi:10.1137/1.9781611977653.ch74,
  title = {A Linkage-based Doubly Imbalanced Graph Learning Framework for Face Clustering},
  author = {Huafeng Yang and Qijie Shen and Xingjian Chen and Fangyi Zhang and Rong Du},
  booktitle = {SIAM International Conference on Data Mining},
  pages = {658--666},
  year = {2023},
  doi = {10.1137/1.9781611977653.ch74},
  URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977653.ch74},
  eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977653.ch74},
  pdf={https://arxiv.org/pdf/2107.02477},
  preview={a_linkage-based.png},
  abstract={In recent years, benefiting from the expressive power of Graph Convolutional Networks (GCNs), significant breakthroughs have been made in face clustering area. However, rare attention has been paid to GCN-based clustering on imbalanced data. Although imbalance problem has been extensively studied, the impact of imbalanced data on GCN- based linkage prediction task is quite different, which would cause problems in two aspects: imbalanced linkage labels and biased graph representations. The former is similar to that in classic image classification task, but the latter is a particular problem in GCN-based clustering via linkage prediction. Significantly biased graph representations in training can cause catastrophic over-fitting of a GCN model. To tackle these challenges, we propose a linkage-based doubly imbalanced graph learning framework for face clustering. In this framework, we evaluate the feasibility of those existing methods for imbalanced image classification problem on GCNs, and present a new method to alleviate the imbalanced labels and also augment graph representations using a Reverse-Imbalance Weighted Sampling (RIWS) strategy. With the RIWS strategy, probability-based class balancing weights could ensure the overall distribution of positive and negative samples; in addition, weighted random sampling provides diverse subgraph structures, which effectively alleviates the over-fitting problem and improves the representation ability of GCNs. Extensive experiments on series of imbalanced benchmark datasets synthesized from MS-Celeb-1M and DeepFashion demonstrate the effectiveness and generality of our proposed method.}
}

@inproceedings{wang2022robust,
  title = {Robust Graph Structure Learning via Multiple Statistical Tests},
  author={Yaohua Wang and Fangyi Zhang and Ming Lin and Senzhang Wang and Xiuyu Sun and Rong Jin},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages = {32083--32096},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/cf7700139af1fa346d2f57f1f5c26c18-Paper-Conference.pdf},
  volume = {35},
  year = {2022},
  selected={true},
  pdf={https://proceedings.neurips.cc/paper_files/paper/2022/file/cf7700139af1fa346d2f57f1f5c26c18-Paper-Conference.pdf},
  preview={Robust_Graph_Structure.png},
  abstract={Graph structure learning aims to learn connectivity in a graph from data. It is particularly important for many computer vision related tasks since no explicit graph structure is available for images for most cases. A natural way to construct a graph among images is to treat each image as a node and assign pairwise image similarities as weights to corresponding edges. It is well known that pairwise similarities between images are sensitive to the noise in feature representations, leading to unreliable graph structures. We address this problem from the viewpoint of statistical tests. By viewing the feature vector of each node as an independent sample, the decision of whether creating an edge between two nodes based on their similarity in feature representation can be thought as a single statistical test. To improve the robustness in the decision of creating an edge, multiple samples are drawn and integrated by multiple statistical tests to generate a more reliable similarity measure, consequentially more reliable graph structure. The corresponding elegant matrix form named îˆ®-Attention is designed for efficiency. The effectiveness of multiple tests for graph structure learning is verified both theoretically and empirically on multiple clustering and ReID benchmark datasets.}
}

@inproceedings{wang2022adanets,
  title={Ada-{NETS}: Face Clustering via Adaptive Neighbour Discovery in the Structure Space},
  author={Yaohua Wang and Yaobin Zhang and Fangyi Zhang and Senzhang Wang and Ming Lin and Yuqi Zhang and Xiuyu Sun},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022},
  url={https://openreview.net/forum?id=QJWVP4CTmW4},
  selected={true},
  pdf={https://arxiv.org/pdf/2202.03800},
  preview={Face_Clustering_via.png},
  abstract={Face clustering has attracted rising research interest recently to take advantage of massive amounts of face images on the web. State-of-the-art performance has been achieved by Graph Convolutional Networks (GCN) due to their powerful representation capacity. However, existing GCN-based methods build face graphs mainly according to kNN relations in the feature space, which may lead to a lot of noise edges connecting two faces of different classes. The face features will be polluted when messages pass along these noise edges, thus degrading the performance of GCNs. In this paper, a novel algorithm named Ada-NETS is proposed to cluster faces by constructing clean graphs for GCNs. In Ada-NETS, each face is transformed to a new structure space, obtaining robust features by considering face features of the neighbour images. Then, an adaptive neighbour discovery strategy is proposed to determine a proper number of edges connecting to each face image. It significantly reduces the noise edges while maintaining the good ones to build a graph with clean yet rich edges for GCNs to cluster faces. Experiments on multiple public clustering datasets show that Ada-NETS significantly outperforms current state-of-the-art methods, proving its superiority and generalization.}
}

@INPROCEEDINGS{9746149,
  title={Jmpnet: Joint Motion Prediction for Learning-Based Video Compression},
  author={Dongyang Li and Zhenhong Sun and Zhiyu Tan and Xiuyu Sun and Fangyi Zhang and Yichen Qian and Hao Li},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  year={2022},
  pages={1855--1859},
  doi={10.1109/ICASSP43922.2022.9746149},
  pdf={https://ieeexplore.ieee.org/document/9746149},
  preview={brownian-motion.gif},
  abstract={In recent years, more attention is attracted by learning-based approaches in the field of video compression. Recent methods of this kind normally consist of three major components: intra-frame network, motion prediction network, and residual network, among which the motion prediction part is particularly critical for video compression. Benefiting from the optical flow which enables dense motion prediction, recent methods have shown competitive performance compared with traditional codecs. However, problems such as tail shadow and background distortion in the predicted frame remain unsolved. To tackle these problems, JMPNet is introduced in this paper to provide more accurate motion information by using both optical flow and dynamic local filter as well as an attention map to further fuse these motion information in a smarter way. Experimental results show that the proposed method surpasses state-of-the-art (SOTA) rate-distortion (RD) performance in the most data-sets.}
}

@inproceedings{yang2021gcn,
  title={GCN-Based Linkage Prediction for Face Clusteringon Imbalanced Datasets: An Empirical Study},
  author={Huafeng Yang and Xingjian Chen and Fangyi Zhang and Guangyue Hei and Yunjie Wang and Rong Du},
  booktitle={Workshops of the International Joint Conference on Artificial Intelligence},
  year={2021},
  url={https://arxiv.org/abs/2107.02477v2},
  pdf={https://www.researchgate.net/publication/353043011_GCN-Based_Linkage_Prediction_for_Face_Clusteringon_Imbalanced_Datasets_An_Empirical_Study},
  preview={GCN_Based_Linkage.png},
  abstract={In recent years, benefiting from the expressivepower of Graph Convolutional Networks (GCNs),significant breakthroughs have been made in faceclustering. However, rare attention has been paidto GCN-based clustering on imbalanced data. Al-though imbalance problem has been extensivelystudied, the impact of imbalanced data on GCN-based linkage prediction task is quite different,which would cause problems in two aspects: im-balanced linkage labels and biased graph represen-tations. The problem of imbalanced linkage labelsis similar to that in image classification task, but thelatter is a particular problem in GCN-based clus-tering via linkage prediction. Significantly biasedgraph representations in training can cause catas-trophic overfitting of a GCN model. To tacklethese problems, we evaluate the feasibility of thoseexisting methods for imbalanced image classifica-tion problem on graphs with extensive experiments,and present a new method to alleviate the imbal-anced labels and also augment graph representa-tions using a Reverse-Imbalance Weighted Sam-pling (RIWS) strategy, followed with insightfulanalyses and discussions. A series of imbalancedbenchmark datasets synthesized from MS-Celeb-1M and DeepFashion will be openly available.}
}

@inproceedings{10.1145/3474085.3475698,
  title = {Interpolation Variable Rate Image Compression},
  author = {Zhenhong Sun and Zhiyu Tan and Xiuyu Sun and Fangyi Zhang and Yichen Qian and Dongyang Li and Hao Li},
  year = {2021},
  isbn = {9781450386517},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3474085.3475698},
  doi = {10.1145/3474085.3475698},
  booktitle = {ACM International Conference on Multimedia},
  pages = {5574--5582},
  numpages = {9},
  keywords = {learned image compression, interpolation variable rate control, convolutional neural network (cnn)},
  location = {Virtual Event, China},
  pdf={https://arxiv.org/pdf/2109.09280},
  preview={Interpolation_Variable.png},
  abstract={Compression standards have been used to reduce the cost of image storage and transmission for decades. In recent years, learned image compression methods have been proposed and achieved compelling performance to the traditional standards. However, in these methods, a set of different networks are used for various compression rates, resulting in a high cost in model storage and training. Although some variable-rate approaches have been proposed to reduce the cost by using a single network, most of them brought some performance degradation when applying fine rate control. To enable variable-rate control without sacrificing the performance, we propose an efficient Interpolation Variable-Rate (IVR) network, by introducing a handy Interpolation Channel Attention (InterpCA) module in the compression network. With the use of two hyperparameters for rate control and linear interpolation, the InterpCA achieves a fine PSNR interval of 0.001 dB and a fine rate interval of 0.0001 Bits-Per-Pixel (BPP) with 9000 rates in the IVR network. Experimental results demonstrate that the IVR network is the first variable-rate learned method that outperforms VTM 9.0 (intra) in PSNR and Multiscale Structural Similarity (MS-SSIM).}
}

@article{zhang2019adversarial,
  title = {Adversarial discriminative sim-to-real transfer of visuo-motor policies},
  author = {Fangyi Zhang and J{\"u}rgen Leitner and Zongyuan Ge and Michael Milford and Peter Corke},
  journal = {The International Journal of Robotics Research (IJRR)},
  volume = {38},
  number = {10--11},
  pages = {1229--1245},
  year = {2019},
  doi = {10.1177/0278364919870227},
  URL = {https://doi.org/10.1177/0278364919870227},
  selected={true},
  pdf={https://arxiv.org/pdf/1709.05746},
  preview={Adversarial_discriminative.png},
  abstract={Various approaches have been proposed to learn visuo-motor policies for real-world robotic applications. One solution is first learning in simulation then transferring to the real world. In the transfer, most existing approaches need real-world images with labels. However, the labelling process is often expensive or even impractical in many robotic applications. In this paper, we propose an adversarial discriminative sim-to-real transfer approach to reduce the cost of labelling real data. The effectiveness of the approach is demonstrated with modular networks in a table-top object reaching task where a 7 DoF arm is controlled in velocity mode to reach a blue cuboid in clutter through visual observations. The adversarial transfer approach reduced the labelled real data requirement by 50%. Policies can be transferred to real environments with only 93 labelled and 186 unlabelled real images. The transferred visuo-motor policies are robust to novel (not seen in training) objects in clutter and even a moving target, achieving a 97.8% success rate and 1.8 cm control accuracy.}
}

@INPROCEEDINGS{leitner2017acrv,  
  title={The ACRV picking benchmark: A robotic shelf picking benchmark to foster reproducible research},   
  author={J{\"u}rgen Leitner and Adam W. Tow and Niko S{\"u}nderhauf and Jake E. Dean and Joseph W. Durham and Matthew Cooper and Markus Eich and Christopher Lehnert and Ruben Mangels and Christopher McCool and Peter T. Kujala and Lachlan Nicholson and Trung Pham and James Sergeant and Liao Wu and Fangyi Zhang and Ben Upcroft and Peter Corke},  
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},   
  year={2017}, 
  pages={4705--4712},  
  doi={10.1109/ICRA.2017.7989545},
  selected={true},
  pdf={https://arxiv.org/pdf/1609.05258},
  preview={The_ACRV_picking.png},
  abstract={Robotic challenges like the Amazon Picking Challenge (APC) or the DARPA Challenges are an established and important way to drive scientific progress. They make research comparable on a well-defined benchmark with equal test conditions for all participants. However, such challenge events occur only occasionally, are limited to a small number of contestants, and the test conditions are very difficult to replicate after the main event. We present a new physical benchmark challenge for robotic picking: the ACRV Picking Benchmark (APB). Designed to be reproducible, it consists of a set of 42 common objects, a widely available shelf, and exact guidelines for object arrangement using stencils. A well-defined evaluation protocol enables the comparison of \emph{complete} robotic systems -- including perception and manipulation -- instead of sub-systems only. Our paper also describes and reports results achieved by an open baseline system based on a Baxter robot.}
}

@inproceedings{zhang2017acra,
  title={Modular Deep Q Networks for Sim-to-real Transfer of Visuo-motor Policies},
  author={Fangyi Zhang and J{\"u}rgen Leitner and Michael Milford and Peter Corke},
  booktitle={Australasian Conference on Robotics and Automation (ACRA)},
  month={December},
  year={2017},
  institution={Sydney, Australia},
  URL={http://www.araa.asn.au/acra/acra2017/papers/pap146s1-file1.pdf},
  pdf={https://arxiv.org/pdf/1610.06781},
  preview={Modular_Deep_Q.png},
  abstract={While deep learning has had significant successes in computer vision thanks to the abundance of visual data, collecting sufficiently large real-world datasets for robot learning can be costly. To increase the practicality of these techniques on real robots, we propose a modular deep reinforcement learning method capable of transferring models trained in simulation to a real-world robotic task. We introduce a bottleneck between perception and control, enabling the networks to be trained independently, but then merged and fine-tuned in an end-to-end manner to further improve hand-eye coordination. On a canonical, planar visually-guided robot reaching task a fine-tuned accuracy of 1.6 pixels is achieved, a significant improvement over naive transfer (17.5 pixels), showing the potential for more complicated and broader applications. Our method provides a technique for more efficient learning and transfer of visuo-motor policies for real robotic systems without relying entirely on large real-world robot datasets.}
}

@inproceedings{zhang2017cvpr,
  title = {Tuning Modular Networks With Weighted Losses for Hand-Eye Coordination},
  author={Fangyi Zhang and J{\"u}rgen Leitner and Michael Milford and Peter Corke},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={496--497},
  month = {July},
  institution={Honolulu, Hawaii, USA},
  url={http://openaccess.thecvf.com/content_cvpr_2017_workshops/w5/papers/Zhang_Tuning_Modular_Networks_CVPR_2017_paper.pdf},
  year={2017},
  doi={10.1109/CVPRW.2017.74},
  pdf={https://arxiv.org/pdf/1705.05116},
  preview={Tuning_Modular.png},
  abstract={This paper introduces an end-to-end fine-tuning method to improve hand-eye coordination in modular deep visuo-motor policies (modular networks) where each module is trained independently. Benefiting from weighted losses, the fine-tuning method significantly improves the performance of the policies for a robotic planar reaching task.}
}

@article{qiu2016let,
  title={Let the light guide us: VLC-based localization},
  author={Kejie Qiu and Fangyi Zhang and Ming Liu},
  journal={IEEE Robotics \& Automation Magazine},
  volume={23},
  number={4},
  pages={174--183},
  year={2016},
  publisher={IEEE},
  doi={10.1109/MRA.2016.2591833},
  pdf={https://ieeexplore.ieee.org/document/7737037},
  preview={brownian-motion.gif},
  abstract={We propose to use visible-light beacons for low-cost indoor localization. Modulated light-emitting diode (LED) lights are adapted for localization as well as illumination. The proposed solution consists of two components: light-signal decomposition and Bayesian localization.}
}

@inproceedings{zhang2015towards,
  title={Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control},
  author={Fangyi Zhang and J{\"u}rgen Leitner and Michael Milford and Ben Upcroft and Peter Corke},
  booktitle={Australasian Conference on Robotics and Automation (ACRA)},
  month={December},
  year={2015},
  institution={Canberra, Australia},
  url={https://www.araa.asn.au/acra/acra2015/papers/pap168.pdf},
  pdf={https://arxiv.org/pdf/1511.03791},
  preview={Towards_Vision_Based.png},
  abstract={This paper introduces a machine learning based system for controlling a robotic manipulator with visual perception only. The capability to autonomously learn robot controllers solely from raw-pixel images and without any prior knowledge of configuration is shown for the first time. We build upon the success of recent deep reinforcement learning and develop a system for learning target reaching with a three-joint robot manipulator using external visual observation. A Deep Q Network (DQN) was demonstrated to perform target reaching after training in simulation. Transferring the network to real hardware and real observation in a naive approach failed, but experiments show that the network works when replacing camera images with synthetic images.}
}

@inproceedings{zhang2015asynchronous,
  title={Asynchronous blind signal decomposition using tiny-length code for visible light communication-based indoor localization},
  author={Fangyi Zhang and Kejie Qiu and Ming Liu},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  pages={28002805},
  year={2015},
  organization={IEEE},
  doi={10.1109/ICRA.2015.7139580},
  pdf={https://ieeexplore.ieee.org/document/7139580},
  preview={brownian-motion.gif},
  abstract={Indoor localization is a fundamental capability for service robots and indoor applications on mobile devices. To realize that, the cost and performance are of great concern. In this paper, we introduce a lightweight signal encoding and decomposition method for a low-cost and low-power Visible Light Communication (VLC)-based indoor localization system. Firstly, a Gold-sequence-based tiny-length code selection method is introduced for light encoding. Then a correlation-based asynchronous blind light-signal decomposition method is developed for the decomposition of the lights mixed with modulated light sources. It is able to decompose the mixed light-signal package in real-time. The average decomposition time-cost for each frame is 20 ms. By using the decomposition results, the localization system achieves accuracy at 0.56 m. These features outperform other existing low-cost indoor localization approaches, such as WiFiSLAM.}
}

@inproceedings{qiu2015visible,
  title={Visible light communication-based indoor localization using Gaussian process},
  author={Kejie Qiu and Fangyi Zhang and Ming Liu},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={3125--3130},
  organization={IEEE},
  year={2015},
  doi={10.1109/IROS.2015.7353809},
  pdf={https://ieeexplore.ieee.org/document/7353809},
  preview={brownian-motion.gif},
  abstract={For mobile robots and position-based services, such as healthcare service, precise localization is the most fundamental capability while low-cost localization solutions are with increasing need and potentially have a wide market. A low-cost localization solution based on a novel Visible Light Communication (VLC) system for indoor environments is proposed in this paper. A number of modulated LED lights are used as beacons to aid indoor localization additional to illumination. A Gaussian Process(GP) is used to model the intensity distributions of the light sources. A Bayesian localization framework is constructed using the results of the GP, leading to precise localization. Path-planning is hereby feasible by only using the GP variance field, rather than using a metric map. Dijkstra's algorithm-based path-planner is adopted to cope with the practical situations. We demonstrate our localization system by real-time experiments performed on a tablet PC in an indoor environment.}
}

@INPROCEEDINGS{7294062,
  title={Visible light communication-based indoor environment modeling and metric-free path planning}, 
  author={Kejie Qiu and Fangyi Zhang and Ming Liu},
  booktitle={IEEE International Conference on Automation Science and Engineering}, 
  year={2015},
  pages={200--205},
  doi={10.1109/CoASE.2015.7294062},
  pdf={https://ieeexplore.ieee.org/document/7294062},
  preview={brownian-motion.gif},
  abstract={For mobile robots and position-based services, localization is the most fundamental capability while path-planning is an important application based on that. A novel localization and path-planning solution based on a low-cost Visible Light Communication (VLC) system for indoor environments is proposed in this paper. A number of modulated LED lights are used as beacons to aid indoor localization additional to illumination. A Gaussian Process (GP) is used to model the intensity distributions of the light sources. Path-planning is hereby feasible by using the GP variance field, rather than using a metric map. Graph-based path-planners are introduced to cope with the practical situations. We demonstrate our path-planning system by real-time experiments performed on a tablet PC in an indoor environment.}
}